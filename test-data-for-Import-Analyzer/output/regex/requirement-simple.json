{
  "name": "regex",
  "description": "Introduction\n------------\n\nThis regex implementation is backwards-compatible with the standard 're' module, but offers additional functionality.\n\nNote\n----\n\nThe re module's behaviour with zero-width matches changed in Python 3.7, and this module will follow that behaviour when compiled for Python 3.7.\n\nPyPy\n----\n\nThis module is targeted at CPython. It expects that all codepoints are the same width, so it won't behave properly with PyPy outside U+0000..U+007F because PyPy stores strings as UTF-8.\n\nOld vs new behaviour\n--------------------\n\nIn order to be compatible with the re module, this module has 2 behaviours:\n\n* **Version 0** behaviour (old behaviour, compatible with the re module):\n\n  Please note that the re module's behaviour may change over time, and I'll endeavour to match that behaviour in version 0.\n\n  * Indicated by the ``VERSION0`` or ``V0`` flag, or ``(?V0)`` in the pattern.\n\n  * Zero-width matches are not handled correctly in the re module before Python 3.7. The behaviour in those earlier versions is:\n\n    * ``.split`` won't split a string at a zero-width match.\n\n    * ``.sub`` will advance by one character after a zero-width match.\n\n  * Inline flags apply to the entire pattern, and they can't be turned off.\n\n  * Only simple sets are supported.\n\n  * Case-insensitive matches in Unicode use simple case-folding by default.\n\n* **Version 1** behaviour (new behaviour, possibly different from the re module):\n\n  * Indicated by the ``VERSION1`` or ``V1`` flag, or ``(?V1)`` in the pattern.\n\n  * Zero-width matches are handled correctly.\n\n  * Inline flags apply to the end of the group or pattern, and they can be turned off.\n\n  * Nested sets and set operations are supported.\n\n  * Case-insensitive matches in Unicode use full case-folding by default.\n\nIf no version is specified, the regex module will default to ``regex.DEFAULT_VERSION``.\n\nCase-insensitive matches in Unicode\n-----------------------------------\n\nThe regex module supports both simple and full case-folding for case-insensitive matches in Unicode. Use of full case-folding can be turned on using the ``FULLCASE`` or ``F`` flag, or ``(?f)`` in the pattern. Please note that this flag affects how the ``IGNORECASE`` flag works; the ``FULLCASE`` flag itself does not turn on case-insensitive matching.\n\nIn the version 0 behaviour, the flag is off by default.\n\nIn the version 1 behaviour, the flag is on by default.\n\nNested sets and set operations\n------------------------------\n\nIt's not possible to support both simple sets, as used in the re module, and nested sets at the same time because of a difference in the meaning of an unescaped ``\"[\"`` in a set.\n\nFor example, the pattern ``[[a-z]--[aeiou]]`` is treated in the version 0 behaviour (simple sets, compatible with the re module) as:\n\n* Set containing \"[\" and the letters \"a\" to \"z\"\n\n* Literal \"--\"\n\n* Set containing letters \"a\", \"e\", \"i\", \"o\", \"u\"\n\n* Literal \"]\"\n\nbut in the version 1 behaviour (nested sets, enhanced behaviour) as:\n\n* Set which is:\n\n  * Set containing the letters \"a\" to \"z\"\n\n* but excluding:\n\n  * Set containing the letters \"a\", \"e\", \"i\", \"o\", \"u\"\n\nVersion 0 behaviour: only simple sets are supported.\n\nVersion 1 behaviour: nested sets and set operations are supported.\n\nFlags\n-----\n\nThere are 2 kinds of flag: scoped and global. Scoped flags can apply to only part of a pattern and can be turned on or off; global flags apply to the entire pattern and can only be turned on.\n\nThe scoped flags are: ``FULLCASE``, ``IGNORECASE``, ``MULTILINE``, ``DOTALL``, ``VERBOSE``, ``WORD``.\n\nThe global flags are: ``ASCII``, ``BESTMATCH``, ``ENHANCEMATCH``, ``LOCALE``, ``POSIX``, ``REVERSE``, ``UNICODE``, ``VERSION0``, ``VERSION1``.\n\nIf neither the ``ASCII``, ``LOCALE`` nor ``UNICODE`` flag is specified, it will default to ``UNICODE`` if the regex pattern is a Unicode string and ``ASCII`` if it's a bytestring.\n\nThe ``ENHANCEMATCH`` flag makes fuzzy matching attempt to improve the fit of the next match that it finds.\n\nThe ``BESTMATCH`` flag makes fuzzy matching search for the best match instead of the next match.\n\nNotes on named capture groups\n-----------------------------\n\nAll capture groups have a group number, starting from 1.\n\nGroups with the same group name will have the same group number, and groups with a different group name will have a different group number.\n\nThe same name can be used by more than one group, with later captures 'overwriting' earlier captures. All of the captures of the group will be available from the ``captures`` method of the match object.\n\nGroup numbers will be reused across different branches of a branch reset, eg. ``(?|(first)|(second))`` has only group 1. If capture groups have different group names then they will, of course, have different group numbers, eg. ``(?|(?P<foo>first)|(?P<bar>second))`` has group 1 (\"foo\") and group 2 (\"bar\").\n\nIn the regex ``(\\s+)(?|(?P<foo>[A-Z]+)|(\\w+) (?P<foo>[0-9]+)`` there are 2 groups:\n\n* ``(\\s+)`` is group 1.\n\n* ``(?P<foo>[A-Z]+)`` is group 2, also called \"foo\".\n\n* ``(\\w+)`` is group 2 because of the branch reset.\n\n* ``(?P<foo>[0-9]+)`` is group 2 because it's called \"foo\".\n\nIf you want to prevent ``(\\w+)`` from being group 2, you need to name it (different name, different group number).\n\nMultithreading\n--------------\n\nThe regex module releases the GIL during matching on instances of the built-in (immutable) string classes, enabling other Python threads to run concurrently. It is also possible to force the regex module to release the GIL during matching by calling the matching methods with the keyword argument ``concurrent=True``. The behaviour is undefined if the string changes during matching, so use it *only* when it is guaranteed that that won't happen.\n\nUnicode\n-------\n\nThis module supports Unicode 13.0.0.\n\nFull Unicode case-folding is supported.\n\nAdditional features\n-------------------\n\nThe issue numbers relate to the Python bug tracker, except where listed as \"Hg issue\".\n\nAdded support for lookaround in conditional pattern (`Hg issue 163 <https://bitbucket.org/mrabarnett/mrab-regex/issues/163>`_)\n^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n\nThe test of a conditional pattern can now be a lookaround.\n\nExamples:\n\n.. sourcecode:: python\n\n  >>> regex.match(r'(?(?=\\d)\\d+|\\w+)', '123abc')\n  <regex.Match object; span=(0, 3), match='123'>\n  >>> regex.match(r'(?(?=\\d)\\d+|\\w+)', 'abc123')\n  <regex.Match object; span=(0, 6), match='abc123'>\n\nThis is not quite the same as putting a lookaround in the first branch of a pair of alternatives.\n\nExamples:\n\n.. sourcecode:: python\n\n  >>> print(regex.match(r'(?:(?=\\d)\\d+\\b|\\w+)', '123abc'))\n  <regex.Match object; span=(0, 6), match='123abc'>\n  >>> print(regex.match(r'(?(?=\\d)\\d+\\b|\\w+)', '123abc'))\n  None\n\nIn the first example, the lookaround matched, but the remainder of the first branch failed to match, and so the second branch was attempted, whereas in the second example, the lookaround matched, and the first branch failed to match, but the second branch was **not** attempted.\n\nAdded POSIX matching (leftmost longest) (`Hg issue 150 <https://bitbucket.org/mrabarnett/mrab-regex/issues/150>`_)\n^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n\nThe POSIX standard for regex is to return the leftmost longest match. This can be turned on using the ``POSIX`` flag (``(?p)``).\n\nExamples:\n\n.. sourcecode:: python\n\n  >>> # Normal matching.\n  >>> regex.search(r'Mr|Mrs', 'Mrs')\n  <regex.Match object; span=(0, 2), match='Mr'>\n  >>> regex.search(r'one(self)?(selfsufficient)?', 'oneselfsufficient')\n  <regex.Match object; span=(0, 7), match='oneself'>\n  >>> # POSIX matching.\n  >>> regex.search(r'(?p)Mr|Mrs', 'Mrs')\n  <regex.Match object; span=(0, 3), match='Mrs'>\n  >>> regex.search(r'(?p)one(self)?(selfsufficient)?', 'oneselfsufficient')\n  <regex.Match object; span=(0, 17), match='oneselfsufficient'>\n\nNote that it will take longer to find matches because when it finds a match at a certain position, it won't return that immediately, but will keep looking to see if there's another longer match there.\n\nAdded ``(?(DEFINE)...)`` (`Hg issue 152 <https://bitbucket.org/mrabarnett/mrab-regex/issues/152>`_)\n^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n\nIf there's no group called \"DEFINE\", then ... will be ignored, but any group definitions within it will be available.\n\nExamples:\n\n.. sourcecode:: python\n\n  >>> regex.search(r'(?(DEFINE)(?P<quant>\\d+)(?P<item>\\w+))(?&quant) (?&item)', '5 elephants')\n  <regex.Match object; span=(0, 11), match='5 elephants'>\n\nAdded ``(*PRUNE)``, ``(*SKIP)`` and ``(*FAIL)`` (`Hg issue 153 <https://bitbucket.org/mrabarnett/mrab-regex/issues/153>`_)\n^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n\n``(*PRUNE)`` discards the backtracking info up to that point. When used in an atomic group or a lookaround, it won't affect the enclosing pattern.\n\n``(*SKIP)`` is similar to ``(*PRUNE)``, except that it also sets where in the text the next attempt to match will start. When used in an atomic group or a lookaround, it won't affect the enclosing pattern.\n\n``(*FAIL)`` causes immediate backtracking. ``(*F)`` is a permitted abbreviation.\n\nAdded ``\\K`` (`Hg issue 151 <https://bitbucket.org/mrabarnett/mrab-regex/issues/151>`_)\n^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n\nKeeps the part of the entire match after the position where ``\\K`` occurred; the part before it is discarded.\n\nIt does not affect what capture groups return.\n\nExamples:\n\n.. sourcecode:: python\n\n  >>> m = regex.search(r'(\\w\\w\\K\\w\\w\\w)', 'abcdef')\n  >>> m[0]\n  'cde'\n  >>> m[1]\n  'abcde'\n  >>>\n  >>> m = regex.search(r'(?r)(\\w\\w\\K\\w\\w\\w)', 'abcdef')\n  >>> m[0]\n  'bc'\n  >>> m[1]\n  'bcdef'\n\nAdded capture subscripting for ``expandf`` and ``subf``/``subfn`` (`Hg issue 133 <https://bitbucket.org/mrabarnett/mrab-regex/issues/133>`_)\n^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n\nYou can now use subscripting to get the captures of a repeated capture group.\n\nExamples:\n\n.. sourcecode:: python\n\n  >>> m = regex.match(r\"(\\w)+\", \"abc\")\n  >>> m.expandf(\"{1}\")\n  'c'\n  >>> m.expandf(\"{1[0]} {1[1]} {1[2]}\")\n  'a b c'\n  >>> m.expandf(\"{1[-1]} {1[-2]} {1[-3]}\")\n  'c b a'\n  >>>\n  >>> m = regex.match(r\"(?P<letter>\\w)+\", \"abc\")\n  >>> m.expandf(\"{letter}\")\n  'c'\n  >>> m.expandf(\"{letter[0]} {letter[1]} {letter[2]}\")\n  'a b c'\n  >>> m.expandf(\"{letter[-1]} {letter[-2]} {letter[-3]}\")\n  'c b a'\n\nAdded support for referring to a group by number using ``(?P=...)``.\n^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n\nThis is in addition to the existing ``\\g<...>``.\n\nFixed the handling of locale-sensitive regexes.\n^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n\nThe ``LOCALE`` flag is intended for legacy code and has limited support. You're still recommended to use Unicode instead.\n\nAdded partial matches (`Hg issue 102 <https://bitbucket.org/mrabarnett/mrab-regex/issues/102>`_)\n^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n\nA partial match is one that matches up to the end of string, but that string has been truncated and you want to know whether a complete match could be possible if the string had not been truncated.\n\nPartial matches are supported by ``match``, ``search``, ``fullmatch`` and ``finditer`` with the ``partial`` keyword argument.\n\nMatch objects have a ``partial`` attribute, which is ``True`` if it's a partial match.\n\nFor example, if you wanted a user to enter a 4-digit number and check it character by character as it was being entered:\n\n.. sourcecode:: python\n\n  >>> pattern = regex.compile(r'\\d{4}')\n\n  >>> # Initially, nothing has been entered:\n  >>> print(pattern.fullmatch('', partial=True))\n  <regex.Match object; span=(0, 0), match='', partial=True>\n\n  >>> # An empty string is OK, but it's only a partial match.\n  >>> # The user enters a letter:\n  >>> print(pattern.fullmatch('a', partial=True))\n  None\n  >>> # It'll never match.\n\n  >>> # The user deletes that and enters a digit:\n  >>> print(pattern.fullmatch('1', partial=True))\n  <regex.Match object; span=(0, 1), match='1', partial=True>\n  >>> # It matches this far, but it's only a partial match.\n\n  >>> # The user enters 2 more digits:\n  >>> print(pattern.fullmatch('123', partial=True))\n  <regex.Match object; span=(0, 3), match='123', partial=True>\n  >>> # It matches this far, but it's only a partial match.\n\n  >>> # The user enters another digit:\n  >>> print(pattern.fullmatch('1234', partial=True))\n  <regex.Match object; span=(0, 4), match='1234'>\n  >>> # It's a complete match.\n\n  >>> # If the user enters another digit:\n  >>> print(pattern.fullmatch('12345', partial=True))\n  None\n  >>> # It's no longer a match.\n\n  >>> # This is a partial match:\n  >>> pattern.match('123', partial=True).partial\n  True\n\n  >>> # This is a complete match:\n  >>> pattern.match('1233', partial=True).partial\n  False\n\n``*`` operator not working correctly with sub() (`Hg issue 106 <https://bitbucket.org/mrabarnett/mrab-regex/issues/106>`_)\n^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n\nSometimes it's not clear how zero-width matches should be handled. For example, should ``.*`` match 0 characters directly after matching >0 characters?\n\nExamples:\n\n.. sourcecode:: python\n\n  # Python 3.7 and later\n  >>> regex.sub('.*', 'x', 'test')\n  'xx'\n  >>> regex.sub('.*?', '|', 'test')\n  '|||||||||'\n\n  # Python 3.6 and earlier\n  >>> regex.sub('(?V0).*', 'x', 'test')\n  'x'\n  >>> regex.sub('(?V1).*', 'x', 'test')\n  'xx'\n  >>> regex.sub('(?V0).*?', '|', 'test')\n  '|t|e|s|t|'\n  >>> regex.sub('(?V1).*?', '|', 'test')\n  '|||||||||'\n\nAdded ``capturesdict`` (`Hg issue 86 <https://bitbucket.org/mrabarnett/mrab-regex/issues/86>`_)\n^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n\n``capturesdict`` is a combination of ``groupdict`` and ``captures``:\n\n``groupdict`` returns a dict of the named groups and the last capture of those groups.\n\n``captures`` returns a list of all the captures of a group\n\n``capturesdict`` returns a dict of the named groups and lists of all the captures of those groups.\n\nExamples:\n\n.. sourcecode:: python\n\n  >>> m = regex.match(r\"(?:(?P<word>\\w+) (?P<digits>\\d+)\\n)+\", \"one 1\\ntwo 2\\nthree 3\\n\")\n  >>> m.groupdict()\n  {'word': 'three', 'digits': '3'}\n  >>> m.captures(\"word\")\n  ['one', 'two', 'three']\n  >>> m.captures(\"digits\")\n  ['1', '2', '3']\n  >>> m.capturesdict()\n  {'word': ['one', 'two', 'three'], 'digits': ['1', '2', '3']}\n\nAllow duplicate names of groups (`Hg issue 87 <https://bitbucket.org/mrabarnett/mrab-regex/issues/87>`_)\n^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n\nGroup names can now be duplicated.\n\nExamples:\n\n.. sourcecode:: python\n\n  >>> # With optional groups:\n  >>>\n  >>> # Both groups capture, the second capture 'overwriting' the first.\n  >>> m = regex.match(r\"(?P<item>\\w+)? or (?P<item>\\w+)?\", \"first or second\")\n  >>> m.group(\"item\")\n  'second'\n  >>> m.captures(\"item\")\n  ['first', 'second']\n  >>> # Only the second group captures.\n  >>> m = regex.match(r\"(?P<item>\\w+)? or (?P<item>\\w+)?\", \" or second\")\n  >>> m.group(\"item\")\n  'second'\n  >>> m.captures(\"item\")\n  ['second']\n  >>> # Only the first group captures.\n  >>> m = regex.match(r\"(?P<item>\\w+)? or (?P<item>\\w+)?\", \"first or \")\n  >>> m.group(\"item\")\n  'first'\n  >>> m.captures(\"item\")\n  ['first']\n  >>>\n  >>> # With mandatory groups:\n  >>>\n  >>> # Both groups capture, the second capture 'overwriting' the first.\n  >>> m = regex.match(r\"(?P<item>\\w*) or (?P<item>\\w*)?\", \"first or second\")\n  >>> m.group(\"item\")\n  'second'\n  >>> m.captures(\"item\")\n  ['first', 'second']\n  >>> # Again, both groups capture, the second capture 'overwriting' the first.\n  >>> m = regex.match(r\"(?P<item>\\w*) or (?P<item>\\w*)\", \" or second\")\n  >>> m.group(\"item\")\n  'second'\n  >>> m.captures(\"item\")\n  ['', 'second']\n  >>> # And yet again, both groups capture, the second capture 'overwriting' the first.\n  >>> m = regex.match(r\"(?P<item>\\w*) or (?P<item>\\w*)\", \"first or \")\n  >>> m.group(\"item\")\n  ''\n  >>> m.captures(\"item\")\n  ['first', '']\n\nAdded ``fullmatch`` (`issue #16203 <https://bugs.python.org/issue16203>`_)\n^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n\n``fullmatch`` behaves like ``match``, except that it must match all of the string.\n\nExamples:\n\n.. sourcecode:: python\n\n  >>> print(regex.fullmatch(r\"abc\", \"abc\").span())\n  (0, 3)\n  >>> print(regex.fullmatch(r\"abc\", \"abcx\"))\n  None\n  >>> print(regex.fullmatch(r\"abc\", \"abcx\", endpos=3).span())\n  (0, 3)\n  >>> print(regex.fullmatch(r\"abc\", \"xabcy\", pos=1, endpos=4).span())\n  (1, 4)\n  >>>\n  >>> regex.match(r\"a.*?\", \"abcd\").group(0)\n  'a'\n  >>> regex.fullmatch(r\"a.*?\", \"abcd\").group(0)\n  'abcd'\n\nAdded ``subf`` and ``subfn``\n^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n\n``subf`` and ``subfn`` are alternatives to ``sub`` and ``subn`` respectively. When passed a replacement string, they treat it as a format string.\n\nExamples:\n\n.. sourcecode:: python\n\n  >>> regex.subf(r\"(\\w+) (\\w+)\", \"{0} => {2} {1}\", \"foo bar\")\n  'foo bar => bar foo'\n  >>> regex.subf(r\"(?P<word1>\\w+) (?P<word2>\\w+)\", \"{word2} {word1}\", \"foo bar\")\n  'bar foo'\n\nAdded ``expandf`` to match object\n^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n\n``expandf`` is an alternative to ``expand``. When passed a replacement string, it treats it as a format string.\n\nExamples:\n\n.. sourcecode:: python\n\n  >>> m = regex.match(r\"(\\w+) (\\w+)\", \"foo bar\")\n  >>> m.expandf(\"{0} => {2} {1}\")\n  'foo bar => bar foo'\n  >>>\n  >>> m = regex.match(r\"(?P<word1>\\w+) (?P<word2>\\w+)\", \"foo bar\")\n  >>> m.expandf(\"{word2} {word1}\")\n  'bar foo'\n\nDetach searched string\n^^^^^^^^^^^^^^^^^^^^^^\n\nA match object contains a reference to the string that was searched, via its ``string`` attribute. The ``detach_string`` method will 'detach' that string, making it available for garbage collection, which might save valuable memory if that string is very large.\n\nExample:\n\n.. sourcecode:: python\n\n  >>> m = regex.search(r\"\\w+\", \"Hello world\")\n  >>> print(m.group())\n  Hello\n  >>> print(m.string)\n  Hello world\n  >>> m.detach_string()\n  >>> print(m.group())\n  Hello\n  >>> print(m.string)\n  None\n\nRecursive patterns (`Hg issue 27 <https://bitbucket.org/mrabarnett/mrab-regex/issues/27>`_)\n^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n\nRecursive and repeated patterns are supported.\n\n``(?R)`` or ``(?0)`` tries to match the entire regex recursively. ``(?1)``, ``(?2)``, etc, try to match the relevant capture group.\n\n``(?&name)`` tries to match the named capture group.\n\nExamples:\n\n.. sourcecode:: python\n\n  >>> regex.match(r\"(Tarzan|Jane) loves (?1)\", \"Tarzan loves Jane\").groups()\n  ('Tarzan',)\n  >>> regex.match(r\"(Tarzan|Jane) loves (?1)\", \"Jane loves Tarzan\").groups()\n  ('Jane',)\n\n  >>> m = regex.search(r\"(\\w)(?:(?R)|(\\w?))\\1\", \"kayak\")\n  >>> m.group(0, 1, 2)\n  ('kayak', 'k', None)\n\nThe first two examples show how the subpattern within the capture group is reused, but is _not_ itself a capture group. In other words, ``\"(Tarzan|Jane) loves (?1)\"`` is equivalent to ``\"(Tarzan|Jane) loves (?:Tarzan|Jane)\"``.\n\nIt's possible to backtrack into a recursed or repeated group.\n\nYou can't call a group if there is more than one group with that group name or group number (``\"ambiguous group reference\"``).\n\nThe alternative forms ``(?P>name)`` and ``(?P&name)`` are also supported.\n\nFull Unicode case-folding is supported.\n^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n\nIn version 1 behaviour, the regex module uses full case-folding when performing case-insensitive matches in Unicode.\n\nExamples (in Python 3):\n\n.. sourcecode:: python\n\n  >>> regex.match(r\"(?iV1)strasse\", \"stra\\N{LATIN SMALL LETTER SHARP S}e\").span()\n  (0, 6)\n  >>> regex.match(r\"(?iV1)stra\\N{LATIN SMALL LETTER SHARP S}e\", \"STRASSE\").span()\n  (0, 7)\n\nIn version 0 behaviour, it uses simple case-folding for backward compatibility with the re module.\n\nApproximate \"fuzzy\" matching (`Hg issue 12 <https://bitbucket.org/mrabarnett/mrab-regex/issues/12>`_, `Hg issue 41 <https://bitbucket.org/mrabarnett/mrab-regex/issues/41>`_, `Hg issue 109 <https://bitbucket.org/mrabarnett/mrab-regex/issues/109>`_)\n^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n\nRegex usually attempts an exact match, but sometimes an approximate, or \"fuzzy\", match is needed, for those cases where the text being searched may contain errors in the form of inserted, deleted or substituted characters.\n\nA fuzzy regex specifies which types of errors are permitted, and, optionally, either the minimum and maximum or only the maximum permitted number of each type. (You cannot specify only a minimum.)\n\nThe 3 types of error are:\n\n* Insertion, indicated by \"i\"\n\n* Deletion, indicated by \"d\"\n\n* Substitution, indicated by \"s\"\n\nIn addition, \"e\" indicates any type of error.\n\nThe fuzziness of a regex item is specified between \"{\" and \"}\" after the item.\n\nExamples:\n\n* ``foo`` match \"foo\" exactly\n\n* ``(?:foo){i}`` match \"foo\", permitting insertions\n\n* ``(?:foo){d}`` match \"foo\", permitting deletions\n\n* ``(?:foo){s}`` match \"foo\", permitting substitutions\n\n* ``(?:foo){i,s}`` match \"foo\", permitting insertions and substitutions\n\n* ``(?:foo){e}`` match \"foo\", permitting errors\n\nIf a certain type of error is specified, then any type not specified will **not** be permitted.\n\nIn the following examples I'll omit the item and write only the fuzziness:\n\n* ``{d<=3}`` permit at most 3 deletions, but no other types\n\n* ``{i<=1,s<=2}`` permit at most 1 insertion and at most 2 substitutions, but no deletions\n\n* ``{1<=e<=3}`` permit at least 1 and at most 3 errors\n\n* ``{i<=2,d<=2,e<=3}`` permit at most 2 insertions, at most 2 deletions, at most 3 errors in total, but no substitutions\n\nIt's also possible to state the costs of each type of error and the maximum permitted total cost.\n\nExamples:\n\n* ``{2i+2d+1s<=4}`` each insertion costs 2, each deletion costs 2, each substitution costs 1, the total cost must not exceed 4\n\n* ``{i<=1,d<=1,s<=1,2i+2d+1s<=4}`` at most 1 insertion, at most 1 deletion, at most 1 substitution; each insertion costs 2, each deletion costs 2, each substitution costs 1, the total cost must not exceed 4\n\nYou can also use \"<\" instead of \"<=\" if you want an exclusive minimum or maximum.\n\nYou can add a test to perform on a character that's substituted or inserted.\n\nExamples:\n\n* ``{s<=2:[a-z]}`` at most 2 substitutions, which must be in the character set ``[a-z]``.\n\n* ``{s<=2,i<=3:\\d}`` at most 2 substitutions, at most 3 insertions, which must be digits.\n\nBy default, fuzzy matching searches for the first match that meets the given constraints. The ``ENHANCEMATCH`` flag will cause it to attempt to improve the fit (i.e. reduce the number of errors) of the match that it has found.\n\nThe ``BESTMATCH`` flag will make it search for the best match instead.\n\nFurther examples to note:\n\n* ``regex.search(\"(dog){e}\", \"cat and dog\")[1]`` returns ``\"cat\"`` because that matches ``\"dog\"`` with 3 errors (an unlimited number of errors is permitted).\n\n* ``regex.search(\"(dog){e<=1}\", \"cat and dog\")[1]`` returns ``\" dog\"`` (with a leading space) because that matches ``\"dog\"`` with 1 error, which is within the limit.\n\n* ``regex.search(\"(?e)(dog){e<=1}\", \"cat and dog\")[1]`` returns ``\"dog\"`` (without a leading space) because the fuzzy search matches ``\" dog\"`` with 1 error, which is within the limit, and the ``(?e)`` then it attempts a better fit.\n\nIn the first two examples there are perfect matches later in the string, but in neither case is it the first possible match.\n\nThe match object has an attribute ``fuzzy_counts`` which gives the total number of substitutions, insertions and deletions.\n\n.. sourcecode:: python\n\n  >>> # A 'raw' fuzzy match:\n  >>> regex.fullmatch(r\"(?:cats|cat){e<=1}\", \"cat\").fuzzy_counts\n  (0, 0, 1)\n  >>> # 0 substitutions, 0 insertions, 1 deletion.\n\n  >>> # A better match might be possible if the ENHANCEMATCH flag used:\n  >>> regex.fullmatch(r\"(?e)(?:cats|cat){e<=1}\", \"cat\").fuzzy_counts\n  (0, 0, 0)\n  >>> # 0 substitutions, 0 insertions, 0 deletions.\n\nThe match object also has an attribute ``fuzzy_changes`` which gives a tuple of the positions of the substitutions, insertions and deletions.\n\n.. sourcecode:: python\n\n  >>> m = regex.search('(fuu){i<=2,d<=2,e<=5}', 'anaconda foo bar')\n  >>> m\n  <regex.Match object; span=(7, 10), match='a f', fuzzy_counts=(0, 2, 2)>\n  >>> m.fuzzy_changes\n  ([], [7, 8], [10, 11])\n\nWhat this means is that if the matched part of the string had been:\n\n.. sourcecode:: python\n\n  'anacondfuuoo bar'\n\nit would've been an exact match.\n\nHowever, there were insertions at positions 7 and 8:\n\n.. sourcecode:: python\n\n  'anaconda fuuoo bar'\n          ^^\n\nand deletions at positions 10 and 11:\n\n.. sourcecode:: python\n\n  'anaconda f~~oo bar'\n             ^^\n\nSo the actual string was:\n\n.. sourcecode:: python\n\n  'anaconda foo bar'\n\nNamed lists (`Hg issue 11 <https://bitbucket.org/mrabarnett/mrab-regex/issues/11>`_)\n^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n\n``\\L<name>``\n\nThere are occasions where you may want to include a list (actually, a set) of options in a regex.\n\nOne way is to build the pattern like this:\n\n.. sourcecode:: python\n\n  >>> p = regex.compile(r\"first|second|third|fourth|fifth\")\n\nbut if the list is large, parsing the resulting regex can take considerable time, and care must also be taken that the strings are properly escaped and properly ordered, for example, \"cats\" before \"cat\".\n\nThe new alternative is to use a named list:\n\n.. sourcecode:: python\n\n  >>> option_set = [\"first\", \"second\", \"third\", \"fourth\", \"fifth\"]\n  >>> p = regex.compile(r\"\\L<options>\", options=option_set)\n\nThe order of the items is irrelevant, they are treated as a set. The named lists are available as the ``.named_lists`` attribute of the pattern object :\n\n.. sourcecode:: python\n\n  >>> print(p.named_lists)\n  # Python 3\n  {'options': frozenset({'fifth', 'first', 'fourth', 'second', 'third'})}\n  # Python 2\n  {'options': frozenset(['fifth', 'fourth', 'second', 'third', 'first'])}\n\nIf there are any unused keyword arguments, ``ValueError`` will be raised unless you tell it otherwise:\n\n.. sourcecode:: python\n\n  >>> option_set = [\"first\", \"second\", \"third\", \"fourth\", \"fifth\"]\n  >>> p = regex.compile(r\"\\L<options>\", options=option_set, other_options=[])\n  Traceback (most recent call last):\n    File \"<stdin>\", line 1, in <module>\n    File \"C:\\Python37\\lib\\site-packages\\regex\\regex.py\", line 348, in compile\n      return _compile(pattern, flags, ignore_unused, kwargs)\n    File \"C:\\Python37\\lib\\site-packages\\regex\\regex.py\", line 585, in _compile\n      raise ValueError('unused keyword argument {!a}'.format(any_one))\n  ValueError: unused keyword argument 'other_options'\n  >>> p = regex.compile(r\"\\L<options>\", options=option_set, other_options=[], ignore_unused=True)\n  >>>\n\nStart and end of word\n^^^^^^^^^^^^^^^^^^^^^\n\n``\\m`` matches at the start of a word.\n\n``\\M`` matches at the end of a word.\n\nCompare with ``\\b``, which matches at the start or end of a word.\n\nUnicode line separators\n^^^^^^^^^^^^^^^^^^^^^^^\n\nNormally the only line separator is ``\\n`` (``\\x0A``), but if the ``WORD`` flag is turned on then the line separators are ``\\x0D\\x0A``, ``\\x0A``, ``\\x0B``, ``\\x0C`` and ``\\x0D``, plus ``\\x85``, ``\\u2028`` and ``\\u2029`` when working with Unicode.\n\nThis affects the regex dot ``\".\"``, which, with the ``DOTALL`` flag turned off, matches any character except a line separator. It also affects the line anchors ``^`` and ``$`` (in multiline mode).\n\nSet operators\n^^^^^^^^^^^^^\n\n**Version 1 behaviour only**\n\nSet operators have been added, and a set ``[...]`` can include nested sets.\n\nThe operators, in order of increasing precedence, are:\n\n* ``||`` for union (\"x||y\" means \"x or y\")\n\n* ``~~`` (double tilde) for symmetric difference (\"x~~y\" means \"x or y, but not both\")\n\n* ``&&`` for intersection (\"x&&y\" means \"x and y\")\n\n* ``--`` (double dash) for difference (\"x--y\" means \"x but not y\")\n\nImplicit union, ie, simple juxtaposition like in ``[ab]``, has the highest precedence. Thus, ``[ab&&cd]`` is the same as ``[[a||b]&&[c||d]]``.\n\nExamples:\n\n* ``[ab]`` # Set containing 'a' and 'b'\n\n* ``[a-z]`` # Set containing 'a' .. 'z'\n\n* ``[[a-z]--[qw]]`` # Set containing 'a' .. 'z', but not 'q' or 'w'\n\n* ``[a-z--qw]`` # Same as above\n\n* ``[\\p{L}--QW]`` # Set containing all letters except 'Q' and 'W'\n\n* ``[\\p{N}--[0-9]]`` # Set containing all numbers except '0' .. '9'\n\n* ``[\\p{ASCII}&&\\p{Letter}]`` # Set containing all characters which are ASCII and letter\n\nregex.escape (`issue #2650 <https://bugs.python.org/issue2650>`_)\n^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n\nregex.escape has an additional keyword parameter ``special_only``. When True, only 'special' regex characters, such as '?', are escaped.\n\nExamples:\n\n.. sourcecode:: python\n\n  >>> regex.escape(\"foo!?\", special_only=False)\n  'foo\\\\!\\\\?'\n  >>> regex.escape(\"foo!?\", special_only=True)\n  'foo!\\\\?'\n\nregex.escape (`Hg issue 249 <https://bitbucket.org/mrabarnett/mrab-regex/issues/249>`_)\n^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n\nregex.escape has an additional keyword parameter ``literal_spaces``. When True, spaces are not escaped.\n\nExamples:\n\n.. sourcecode:: python\n\n  >>> regex.escape(\"foo bar!?\", literal_spaces=False)\n  'foo\\\\ bar!\\\\?'\n  >>> regex.escape(\"foo bar!?\", literal_spaces=True)\n  'foo bar!\\\\?'\n\nRepeated captures (`issue #7132 <https://bugs.python.org/issue7132>`_)\n^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n\nA match object has additional methods which return information on all the successful matches of a repeated capture group. These methods are:\n\n* ``matchobject.captures([group1, ...])``\n\n  * Returns a list of the strings matched in a group or groups. Compare with ``matchobject.group([group1, ...])``.\n\n* ``matchobject.starts([group])``\n\n  * Returns a list of the start positions. Compare with ``matchobject.start([group])``.\n\n* ``matchobject.ends([group])``\n\n  * Returns a list of the end positions. Compare with ``matchobject.end([group])``.\n\n* ``matchobject.spans([group])``\n\n  * Returns a list of the spans. Compare with ``matchobject.span([group])``.\n\nExamples:\n\n.. sourcecode:: python\n\n  >>> m = regex.search(r\"(\\w{3})+\", \"123456789\")\n  >>> m.group(1)\n  '789'\n  >>> m.captures(1)\n  ['123', '456', '789']\n  >>> m.start(1)\n  6\n  >>> m.starts(1)\n  [0, 3, 6]\n  >>> m.end(1)\n  9\n  >>> m.ends(1)\n  [3, 6, 9]\n  >>> m.span(1)\n  (6, 9)\n  >>> m.spans(1)\n  [(0, 3), (3, 6), (6, 9)]\n\nAtomic grouping (`issue #433030 <https://bugs.python.org/issue433030>`_)\n^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n\n``(?>...)``\n\nIf the following pattern subsequently fails, then the subpattern as a whole will fail.\n\nPossessive quantifiers.\n^^^^^^^^^^^^^^^^^^^^^^^\n\n``(?:...)?+`` ; ``(?:...)*+`` ; ``(?:...)++`` ; ``(?:...){min,max}+``\n\nThe subpattern is matched up to 'max' times. If the following pattern subsequently fails, then all of the repeated subpatterns will fail as a whole. For example, ``(?:...)++`` is equivalent to ``(?>(?:...)+)``.\n\nScoped flags (`issue #433028 <https://bugs.python.org/issue433028>`_)\n^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n\n``(?flags-flags:...)``\n\nThe flags will apply only to the subpattern. Flags can be turned on or off.\n\nDefinition of 'word' character (`issue #1693050 <https://bugs.python.org/issue1693050>`_)\n^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n\nThe definition of a 'word' character has been expanded for Unicode. It now conforms to the Unicode specification at ``http://www.unicode.org/reports/tr29/``.\n\nVariable-length lookbehind\n^^^^^^^^^^^^^^^^^^^^^^^^^^\n\nA lookbehind can match a variable-length string.\n\nFlags argument for regex.split, regex.sub and regex.subn (`issue #3482 <https://bugs.python.org/issue3482>`_)\n^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n\n``regex.split``, ``regex.sub`` and ``regex.subn`` support a 'flags' argument.\n\nPos and endpos arguments for regex.sub and regex.subn\n^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n\n``regex.sub`` and ``regex.subn`` support 'pos' and 'endpos' arguments.\n\n'Overlapped' argument for regex.findall and regex.finditer\n^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n\n``regex.findall`` and ``regex.finditer`` support an 'overlapped' flag which permits overlapped matches.\n\nSplititer\n^^^^^^^^^\n\n``regex.splititer`` has been added. It's a generator equivalent of ``regex.split``.\n\nSubscripting for groups\n^^^^^^^^^^^^^^^^^^^^^^^\n\nA match object accepts access to the captured groups via subscripting and slicing:\n\n.. sourcecode:: python\n\n  >>> m = regex.search(r\"(?P<before>.*?)(?P<num>\\d+)(?P<after>.*)\", \"pqr123stu\")\n  >>> print(m[\"before\"])\n  pqr\n  >>> print(len(m))\n  4\n  >>> print(m[:])\n  ('pqr123stu', 'pqr', '123', 'stu')\n\nNamed groups\n^^^^^^^^^^^^\n\nGroups can be named with ``(?<name>...)`` as well as the current ``(?P<name>...)``.\n\nGroup references\n^^^^^^^^^^^^^^^^\n\nGroups can be referenced within a pattern with ``\\g<name>``. This also allows there to be more than 99 groups.\n\nNamed characters\n^^^^^^^^^^^^^^^^\n\n``\\N{name}``\n\nNamed characters are supported. (Note: only those known by Python's Unicode database are supported.)\n\nUnicode codepoint properties, including scripts and blocks\n^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n\n``\\p{property=value}``; ``\\P{property=value}``; ``\\p{value}`` ; ``\\P{value}``\n\nMany Unicode properties are supported, including blocks and scripts. ``\\p{property=value}`` or ``\\p{property:value}`` matches a character whose property ``property`` has value ``value``. The inverse of ``\\p{property=value}`` is ``\\P{property=value}`` or ``\\p{^property=value}``.\n\nIf the short form ``\\p{value}`` is used, the properties are checked in the order: ``General_Category``, ``Script``, ``Block``, binary property:\n\n* ``Latin``, the 'Latin' script (``Script=Latin``).\n\n* ``BasicLatin``, the 'BasicLatin' block (``Block=BasicLatin``).\n\n* ``Alphabetic``, the 'Alphabetic' binary property (``Alphabetic=Yes``).\n\nA short form starting with ``Is`` indicates a script or binary property:\n\n* ``IsLatin``, the 'Latin' script (``Script=Latin``).\n\n* ``IsAlphabetic``, the 'Alphabetic' binary property (``Alphabetic=Yes``).\n\nA short form starting with ``In`` indicates a block property:\n\n* ``InBasicLatin``, the 'BasicLatin' block (``Block=BasicLatin``).\n\nPOSIX character classes\n^^^^^^^^^^^^^^^^^^^^^^^\n\n``[[:alpha:]]``; ``[[:^alpha:]]``\n\nPOSIX character classes are supported. These are normally treated as an alternative form of ``\\p{...}``.\n\nThe exceptions are ``alnum``, ``digit``, ``punct`` and ``xdigit``, whose definitions are different from those of Unicode.\n\n``[[:alnum:]]`` is equivalent to ``\\p{posix_alnum}``.\n\n``[[:digit:]]`` is equivalent to ``\\p{posix_digit}``.\n\n``[[:punct:]]`` is equivalent to ``\\p{posix_punct}``.\n\n``[[:xdigit:]]`` is equivalent to ``\\p{posix_xdigit}``.\n\nSearch anchor\n^^^^^^^^^^^^^\n\n``\\G``\n\nA search anchor has been added. It matches at the position where each search started/continued and can be used for contiguous matches or in negative variable-length lookbehinds to limit how far back the lookbehind goes:\n\n.. sourcecode:: python\n\n  >>> regex.findall(r\"\\w{2}\", \"abcd ef\")\n  ['ab', 'cd', 'ef']\n  >>> regex.findall(r\"\\G\\w{2}\", \"abcd ef\")\n  ['ab', 'cd']\n\n* The search starts at position 0 and matches 2 letters 'ab'.\n\n* The search continues at position 2 and matches 2 letters 'cd'.\n\n* The search continues at position 4 and fails to match any letters.\n\n* The anchor stops the search start position from being advanced, so there are no more results.\n\nReverse searching\n^^^^^^^^^^^^^^^^^\n\nSearches can now work backwards:\n\n.. sourcecode:: python\n\n  >>> regex.findall(r\".\", \"abc\")\n  ['a', 'b', 'c']\n  >>> regex.findall(r\"(?r).\", \"abc\")\n  ['c', 'b', 'a']\n\nNote: the result of a reverse search is not necessarily the reverse of a forward search:\n\n.. sourcecode:: python\n\n  >>> regex.findall(r\"..\", \"abcde\")\n  ['ab', 'cd']\n  >>> regex.findall(r\"(?r)..\", \"abcde\")\n  ['de', 'bc']\n\nMatching a single grapheme\n^^^^^^^^^^^^^^^^^^^^^^^^^^\n\n``\\X``\n\nThe grapheme matcher is supported. It now conforms to the Unicode specification at ``http://www.unicode.org/reports/tr29/``.\n\nBranch reset\n^^^^^^^^^^^^\n\n``(?|...|...)``\n\nCapture group numbers will be reused across the alternatives, but groups with different names will have different group numbers.\n\nExamples:\n\n.. sourcecode:: python\n\n  >>> regex.match(r\"(?|(first)|(second))\", \"first\").groups()\n  ('first',)\n  >>> regex.match(r\"(?|(first)|(second))\", \"second\").groups()\n  ('second',)\n\nNote that there is only one group.\n\nDefault Unicode word boundary\n^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n\nThe ``WORD`` flag changes the definition of a 'word boundary' to that of a default Unicode word boundary. This applies to ``\\b`` and ``\\B``.\n\nTimeout (Python 3)\n^^^^^^^^^^^^^^^^^^\n\nThe matching methods and functions support timeouts. The timeout (in seconds) applies to the entire operation:\n\n.. sourcecode:: python\n\n  >>> from time import sleep\n  >>>\n  >>> def fast_replace(m):\n  ...     return 'X'\n  ...\n  >>> def slow_replace(m):\n  ...     sleep(0.5)\n  ...     return 'X'\n  ...\n  >>> regex.sub(r'[a-z]', fast_replace, 'abcde', timeout=2)\n  'XXXXX'\n  >>> regex.sub(r'[a-z]', slow_replace, 'abcde', timeout=2)\n  Traceback (most recent call last):\n    File \"<stdin>\", line 1, in <module>\n    File \"C:\\Python37\\lib\\site-packages\\regex\\regex.py\", line 276, in sub\n      endpos, concurrent, timeout)\n  TimeoutError: regex timed out",
  "requires_dist": null,
  "requires_python": "",
  "current_version": "2021.4.4",
  "released_versions": [
    "0.1.20100217",
    "0.1.20100226",
    "0.1.20100305",
    "0.1.20100323",
    "0.1.20100331",
    "0.1.20100706",
    "0.1.20100706.1",
    "0.1.20100709",
    "0.1.20100709.1",
    "0.1.20100719",
    "0.1.20100725",
    "0.1.20100814",
    "0.1.20100816",
    "0.1.20100824",
    "0.1.20100912",
    "0.1.20100913",
    "0.1.20100918",
    "0.1.20101009",
    "0.1.20101029",
    "0.1.20101030",
    "0.1.20101030b",
    "0.1.20101101",
    "0.1.20101102",
    "0.1.20101102a",
    "0.1.20101106",
    "0.1.20101113",
    "0.1.20101120",
    "0.1.20101121",
    "0.1.20101123",
    "0.1.20101130",
    "0.1.20101207",
    "0.1.20101210",
    "0.1.20101224",
    "0.1.20101228",
    "0.1.20101228a",
    "0.1.20101229",
    "0.1.20101230",
    "0.1.20101231",
    "0.1.20110104",
    "0.1.20110106",
    "0.1.20110124",
    "0.1.20110313",
    "0.1.20110314",
    "0.1.20110315",
    "0.1.20110429",
    "0.1.20110502",
    "0.1.20110504",
    "0.1.20110510",
    "0.1.20110514",
    "0.1.20110524",
    "0.1.20110608",
    "0.1.20110608a",
    "0.1.20110609",
    "0.1.20110610",
    "0.1.20110616",
    "0.1.20110623",
    "0.1.20110623a",
    "0.1.20110627",
    "0.1.20110702",
    "0.1.20110717",
    "0.1.20110917",
    "0.1.20110917a",
    "0.1.20110922",
    "0.1.20110922a",
    "0.1.20110927",
    "0.1.20110929",
    "0.1.20111004",
    "0.1.20111005",
    "0.1.20111006",
    "0.1.20111014",
    "0.1.20111103",
    "0.1.20111223",
    "0.1.20120103",
    "0.1.20120105",
    "0.1.20120112",
    "0.1.20120114",
    "0.1.20120115",
    "0.1.20120119",
    "0.1.20120122",
    "0.1.20120123",
    "0.1.20120126",
    "0.1.20120128",
    "0.1.20120129",
    "0.1.20120208",
    "0.1.20120209",
    "0.1.20120301",
    "0.1.20120303",
    "0.1.20120316",
    "0.1.20120317",
    "0.1.20120323",
    "0.1.20120416",
    "0.1.20120502",
    "0.1.20120503",
    "0.1.20120504",
    "0.1.20120506",
    "0.1.20120611",
    "0.1.20120613",
    "0.1.20120705",
    "0.1.20120708",
    "0.1.20120709",
    "0.1.20120710",
    "0.1.20120803",
    "0.1.20120825",
    "0.1.20120904",
    "0.1.20121008",
    "0.1.20121017",
    "0.1.20121031",
    "0.1.20121105",
    "0.1.20121113",
    "0.1.20121120",
    "0.1.20121216",
    "0.1.20130120",
    "0.1.20130124",
    "0.1.20130125",
    "2013-02-16",
    "2013-02-23",
    "2013-03-11",
    "2013-05-21",
    "2013-06-05",
    "2013-06-26",
    "2013-08-04",
    "2013-10-04",
    "2013-10-12",
    "2013-10-21",
    "2013-10-22",
    "2013-10-23",
    "2013-10-24",
    "2013-10-25",
    "2013-10-26",
    "2013-11-29",
    "2013-12-31",
    "2014.01.10",
    "2014.01.20",
    "2014.01.30",
    "2014.02.16",
    "2014.02.19",
    "2014.04.10",
    "2014.05.17",
    "2014.05.23",
    "2014.06.28",
    "2014.08.15",
    "2014.08.28",
    "2014.09.18",
    "2014.09.22",
    "2014.10.01",
    "2014.10.02",
    "2014.10.07",
    "2014.10.09",
    "2014.10.23",
    "2014.10.24",
    "2014.11.03",
    "2014.11.13",
    "2014.11.14",
    "2014.12.15",
    "2014.12.24",
    "2015.03.18",
    "2015.05.07",
    "2015.05.10",
    "2015.05.28",
    "2015.06.02",
    "2015.06.04",
    "2015.06.09",
    "2015.06.10",
    "2015.06.14",
    "2015.06.15",
    "2015.06.19",
    "2015.06.21",
    "2015.06.24",
    "2015.07.12",
    "2015.07.19",
    "2015.09.14",
    "2015.09.15",
    "2015.09.23",
    "2015.09.28",
    "2015.10.01",
    "2015.10.05",
    "2015.10.22",
    "2015.10.29",
    "2015.11.05",
    "2015.11.07",
    "2015.11.08",
    "2015.11.09",
    "2015.11.12",
    "2015.11.14",
    "2015.11.22",
    "2016.01.10",
    "2016.02.23",
    "2016.02.24",
    "2016.02.25",
    "2016.03.02",
    "2016.03.24",
    "2016.03.26",
    "2016.03.31",
    "2016.04.01",
    "2016.04.02",
    "2016.04.03",
    "2016.04.08",
    "2016.04.15",
    "2016.04.25",
    "2016.05.13",
    "2016.05.14",
    "2016.05.15",
    "2016.05.23",
    "2016.06.02",
    "2016.06.05",
    "2016.06.14",
    "2016.06.19",
    "2016.06.24",
    "2016.07.14",
    "2016.07.21",
    "2016.08.27",
    "2016.09.22",
    "2016.10.22",
    "2016.11.18",
    "2016.11.21",
    "2016.12.27",
    "2017.01.12",
    "2017.01.14",
    "2017.01.17",
    "2017.02.08",
    "2017.04.05",
    "2017.04.23",
    "2017.04.29",
    "2017.05.26",
    "2017.06.07",
    "2017.06.20",
    "2017.06.23",
    "2017.07.11",
    "2017.07.26",
    "2017.07.28",
    "2017.09.23",
    "2017.11.08",
    "2017.11.09",
    "2017.12.05",
    "2017.12.09",
    "2017.12.12",
    "2018.01.10",
    "2018.02.03",
    "2018.02.08",
    "2018.02.21",
    "2018.06.06",
    "2018.06.09",
    "2018.06.20",
    "2018.06.21",
    "2018.07.11",
    "2018.08.17",
    "2018.08.29",
    "2018.11.02",
    "2018.11.03",
    "2018.11.06",
    "2018.11.07",
    "2018.11.22",
    "2019.01.23",
    "2019.01.24",
    "2019.02.03",
    "2019.02.05",
    "2019.02.06",
    "2019.02.07",
    "2019.02.18",
    "2019.02.19",
    "2019.02.20",
    "2019.02.21",
    "2019.03.08",
    "2019.03.09",
    "2019.03.12",
    "2019.04.09",
    "2019.04.10",
    "2019.04.12",
    "2019.04.14",
    "2019.05.25",
    "2019.06.02",
    "2019.06.05",
    "2019.06.08",
    "2019.08.19",
    "2019.11.1",
    "2019.12.17",
    "2019.12.18",
    "2019.12.19",
    "2019.12.20",
    "2019.12.9",
    "2020.1.7",
    "2020.1.8",
    "2020.10.11",
    "2020.10.15",
    "2020.10.22",
    "2020.10.23",
    "2020.10.28",
    "2020.11.11",
    "2020.11.13",
    "2020.2.18",
    "2020.2.20",
    "2020.4.4",
    "2020.5.13",
    "2020.5.14",
    "2020.5.7",
    "2020.6.7",
    "2020.6.8",
    "2020.7.14",
    "2020.9.27",
    "2021.3.17",
    "2021.4.4"
  ]
}